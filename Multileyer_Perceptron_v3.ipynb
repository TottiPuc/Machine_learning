{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multileyer_Perceptron-v3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYlIJhtun8otpYYDU9j000",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TottiPuc/Machine_learning/blob/master/Multileyer_Perceptron_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MMidlAtB9cT",
        "colab_type": "text"
      },
      "source": [
        "#Multilayer-Perceptron con tensorflow y keras v3 (Dividiendo los datos de entrenamiento en lotes)\n",
        "En este nuevo notebook vamos a crear una arquitectura de nua red neuronal con TF y keras es una version actual del algoritmo descrito en [multilayer v1](https://github.com/TottiPuc/Machine_learning/blob/master/Multileyer_Perceptron_v1.ipynb). donde para un grande volumen de datos se requiere dividir el dataset en lotes o *batches* para liberar memoria de nuestra maquina"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UuzDF14B3kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC-n22ZqChkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmXvKY3pCmPL",
        "colab_type": "text"
      },
      "source": [
        "Creamos los hiperparametros de la red y los datos sinteticos a ser entrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrjMpY-nCjpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 200000\n",
        "num_empochs = 10\n",
        "learning_rate = 0.001\n",
        "n_batches = 10000\n",
        "batch_size = 100\n",
        "#creamos 200000 datos aleatorios enteros entre 0 y 100\n",
        "x1 = np.random.randint(0,100, size)\n",
        "x2 = np.random.randint(0,100, size)\n",
        "x_train = np.dstack((x1,x2))[0] # concatenamos x1 y x2 y tomamos la primera capa de profundidad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nv-kKypCsoY",
        "colab_type": "text"
      },
      "source": [
        "Creamos una funcion Y que dependa de x para generas nuestros datos historicos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEkKvqAfCpKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b968bc6b-5e87-4f00-b309-2264401cd763"
      },
      "source": [
        "y_train = 3*(x1**(1/2))+2*(x2**2)\n",
        "print( \"estos son los valores de entrenamiento para 'x' y 'y' y sus respectivas dimensiones \")\n",
        "print(\"valores de x {}, con dimension {}\".format(x_train,x_train.shape))\n",
        "print(\"valores de y {}, con dimension {}\".format(y_train,y_train.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "estos son los valores de entrenamiento para 'x' y 'y' y sus respectivas dimensiones \n",
            "valores de x [[40 40]\n",
            " [38 67]\n",
            " [14 75]\n",
            " ...\n",
            " [67  1]\n",
            " [44 15]\n",
            " [85 96]], con dimension (200000, 2)\n",
            "valores de y [ 3218.97366596  8996.49324201 11261.22497216 ...    26.55605832\n",
            "   469.89974874 18459.65863337], con dimension (200000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8G6MDI1DCj8",
        "colab_type": "text"
      },
      "source": [
        "Creamos el modelo con la herramienta keras y su clase sequential que nos permite adicionar capa \n",
        "tras capa dependiendo de lo que queramos construir. A diferencia de la V1 aumentaremos una capa oculta para compensar el tiempo de entrenamiento causado por la división en lotes del conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JliUcmDpCwCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = tf.keras.Sequential()\n",
        "modelo.add(tf.keras.layers.Dense(64, input_shape=(2,), activation='sigmoid'))\n",
        "modelo.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "modelo.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "modelo.add(tf.keras.layers.Dense(2))\n",
        "\n",
        "# creamos el optimizador\n",
        "optimizador = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "#reamos la funcion de custo\n",
        "mse = tf.keras.losses.MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykni7PHFEHSb",
        "colab_type": "text"
      },
      "source": [
        "Compilamos nuestra arquitectura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0AVlPMwEGZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo.compile(optimizador,mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mArjKHnNEPba",
        "colab_type": "text"
      },
      "source": [
        "La nueva variante de este modelo es la creación de lotes en la etapa de entrenamiento para poder liberar memoria en el caso de tener una cantidad grande de datos. Para eso dividiremos nuestros datos en pequeños lotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMNnX7poEOIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "dataset_train = dataset_train.repeat().shuffle(x_train.shape[0]).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeHVE9UKE-T2",
        "colab_type": "text"
      },
      "source": [
        "Para crear la funcion de entrenamiento debemos usar un loop donde iremos almacenando los calculos de los gradientes en cada lote, es este punto el que facilita el uso de esta técnica en modo online."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv98qEOHE9Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1a45bc9d-914e-4ce5-c7c6-af0236943847"
      },
      "source": [
        "print(\"Iniciando el entrenamiento del modelo por favor espere ...\")\n",
        "for i, (batch_xs_train, batch_ys_train) in enumerate(dataset_train.take(n_batches),1):\n",
        "  \n",
        "  #calculamos la predicción y la tasa de error\n",
        "  with tf.GradientTape() as tape:\n",
        "    #prediccion del modelo\n",
        "    y_pred = modelo(batch_xs_train)\n",
        "\n",
        "    #error del modelo\n",
        "    loss = mse(batch_ys_train[0], y_pred[0])\n",
        "\n",
        "    #calculo el gradiente\n",
        "    grads = tape.gradient(loss, modelo.trainable_variables)  # en trainable_variables estan los pesos y bias almacenados en cada pasada\n",
        "\n",
        "    # separamos los gradientes de forma unica\n",
        "    gradientes_process = [g for g in grads]\n",
        "\n",
        "    # obtenemos los gradientes y pesos de cada lote\n",
        "    grads_y_pesos = zip(gradientes_process,modelo.trainable_variables)\n",
        "\n",
        "  # optimizamos los pesos con el valor de los gradientes\n",
        "  optimizador.apply_gradients(grads_y_pesos)\n",
        "\n",
        "print(\"Tasa de rror final del modelo en entrenamiento \",np.mean(loss.numpy()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iniciando el entrenamiento del modelo por favor espere ...\n",
            "Tasa de rror final del modelo en entrenamiento  668660.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9c2TG8LIEYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "752e2e50-6939-4ead-ebf9-17741effcc1b"
      },
      "source": [
        "modelo.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                192       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 25,282\n",
            "Trainable params: 25,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJS-Bo3OMaX9",
        "colab_type": "text"
      },
      "source": [
        "#Evaluando el modelo\n",
        "Generamos nuevos datos sinteticos para evaluar el modelo ( tienen que estar en el mismo rango entre 0 y 100 ya que el entrenamiento fue realizado con este rango de datos) solo que esta vez se usa el mismo concepto de lotes para poder testar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgL7DKqVMRXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x3= np.array([100, 9, 62, 79, 94, 91, 71, 41])\n",
        "x4= np.array([65, 39, 40, 44, 77, 42, 36, 74])\n",
        "x_test = np.dstack((x3, x4))[0]\n",
        "\n",
        "y_test = 3*(x3**(1/2)) + 2*(x4**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3r1DGxcMpWB",
        "colab_type": "text"
      },
      "source": [
        "Generamos los lotes de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmJpvJr4MkXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
        "dataset_test = dataset_test.repeat().shuffle(x_test.shape[0]).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLw8H8rHM-_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85404a61-e026-4947-f414-9a441dde81fb"
      },
      "source": [
        "print(\"Iniciamos la evaluación del modelo\")\n",
        "for i ,(batch_xs_test, batch_ys_test) in enumerate(dataset_test.take(n_batches),1):\n",
        "  y_pred = modelo(batch_xs_test)\n",
        "  loss = mse(batch_ys_test[0], y_pred)\n",
        "print(\"Tasa de erro final de la etapa de test \", np.mean(loss.numpy()))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iniciamos la evaluación del modelo\n",
            "Tasa de erro final de la etapa de test  10420102.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nFAeL5rNtOD",
        "colab_type": "text"
      },
      "source": [
        "Por ultimo hacemos algunas predicciones con nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzhCFZNUNl0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cd223403-9a6e-474d-a6e5-61ce073a53ea"
      },
      "source": [
        "y_pred = modelo.predict(x_test)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "for i in range(5):\n",
        "    print ('''Entrada(x): ({}, {}), Salida(y): ({:.0f}), Predicción del Modelo(y_pred): ({:.0f})'''.format(x1[i], x2[i], y_test[i], y_pred[i][0]))\n",
        "\n",
        "print(\"\\n\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Entrada(x): (42, 27), Salida(y): (8480), Predicción del Modelo(y_pred): (7161)\n",
            "Entrada(x): (60, 13), Salida(y): (3051), Predicción del Modelo(y_pred): (7146)\n",
            "Entrada(x): (0, 17), Salida(y): (3224), Predicción del Modelo(y_pred): (7138)\n",
            "Entrada(x): (98, 81), Salida(y): (3899), Predicción del Modelo(y_pred): (7180)\n",
            "Entrada(x): (4, 97), Salida(y): (11887), Predicción del Modelo(y_pred): (7020)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYDb523HPHs4",
        "colab_type": "text"
      },
      "source": [
        "#Guardando el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8X_yqXrN9xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# con esto se salva modelos\n",
        "modelo.save('modelo-v.3')\n",
        "#con estose carga modelos\n",
        "modelo-v3 = tf.keras.models.load_model('modelo-v.3')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}